# @package models
defaults:
  - segmentation/default

Res16UNet34-L4-early-ade20k:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone:
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            in_feat_attention: 4
            block: ResBlock
            out_feat_img_0: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: out_feat_img_0
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                #checkpointing: cav  # UnimodalBranch gradient checkpointing at train time

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

Res16UNet34-L4-early-ade20k-max:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone:
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            in_feat_attention: 4
            block: ResBlock
            out_feat_img_0: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

Res16UNet34-PointPyramid-early-cityscapes-interpolate:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone:
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            in_feat_attention: 4
            block: ResBlock
            l0: 128
            l1: 64
            l2: 128
            l3: 256
            l4: 512
            l0_map: 32
            l1_map: 32
            l2_map: 64
            l3_map: 128
            l4_map: 256

        down_conv:
            n_early_conv: 5
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + l0_map + l1_map + l2_map + l3_map + l4_map, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: [
                        CityscapesResNet18Layer0,
                        CityscapesResNet18Layer1,
                        CityscapesResNet18Layer2,
                        CityscapesResNet18Layer3,
                        CityscapesResNet18Layer4 ]
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: [ l0, l1, l2, l3, l4 ]
                    out_mod: [ l0_map, l1_map, l2_map, l3_map, l4_map ]
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: [ 0, 1, 2, 3, 4 ]
                out_channels: [
                        FEAT + l0_map,
                        FEAT + l0_map + l1_map,
                        FEAT + l0_map + l1_map + l2_map,
                        FEAT + l0_map + l1_map + l2_map + l3_map,
                        FEAT + l0_map + l1_map + l2_map + l3_map + l4_map ]  # This is necessary to support batches with no images
                checkpointing: c  # UnimodalBranch gradient checkpointing at train time
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

Res16UNet34-PointPyramid-early-max-cityscapes-interpolate:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone:
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            in_feat_attention: 4
            block: ResBlock
            l0: 128
            l1: 64
            l2: 128
            l3: 256
            l4: 512
            l0_map: 128
            l1_map: 64
            l2_map: 128
            l3_map: 256
            l4_map: 512

        down_conv:
            n_early_conv: 5
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + l0_map + l1_map + l2_map + l3_map + l4_map, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: [
                        CityscapesResNet18Layer0,
                        CityscapesResNet18Layer1,
                        CityscapesResNet18Layer2,
                        CityscapesResNet18Layer3,
                        CityscapesResNet18Layer4 ]
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: [ 0, 1, 2, 3, 4 ]
                out_channels: [
                        FEAT + l0_map,
                        FEAT + l0_map + l1_map,
                        FEAT + l0_map + l1_map + l2_map,
                        FEAT + l0_map + l1_map + l2_map + l3_map,
                        FEAT + l0_map + l1_map + l2_map + l3_map + l4_map ]  # This is necessary to support batches with no images
                checkpointing: c  # UnimodalBranch gradient checkpointing at train time
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]