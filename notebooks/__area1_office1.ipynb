{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.datasets.segmentation.multimodal.s3dis_area1_office1 import S3DISFusedDataset\n",
    "from torch_points3d.datasets.segmentation.multimodal import IGNORE_LABEL\n",
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data\n",
    "\n",
    "# import plotly.offline as pyo\n",
    "# pyo.init_notebook_mode()\n",
    "import plotly.io as pio\n",
    "# pio.renderers\n",
    "pio.renderers.default = 'jupyterlab'  # for local jupyterlab\n",
    "\n",
    "# Ror remote HPC jupyterhub.\n",
    "# Other working (but seemingly slower) options are: 'sphinx_gallery' and 'iframe'\n",
    "# pio.renderers.default = 'iframe_connected' \n",
    "\n",
    "_ = torch.cuda.is_available()\n",
    "_ = torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch import Tensor\n",
    "\n",
    "OBJECT_COLOR = [\n",
    "        [233, 229, 107],  #'ceiling' .-> .yellow\n",
    "        [95, 156, 196],  #'floor' .-> . blue\n",
    "        [179, 116, 81],  #'wall'  ->  brown\n",
    "        [241, 149, 131],  #'beam'  ->  salmon\n",
    "        [81, 163, 148],  #'column'  ->  bluegreen\n",
    "        [77, 174, 84],  #'window'  ->  bright green\n",
    "        [108, 135, 75],  #'door'   ->  dark green\n",
    "        [41, 49, 101],  #'chair'  ->  darkblue\n",
    "        [79, 79, 76],  #'table'  ->  dark grey\n",
    "        [223, 52, 52],  #'bookcase'  ->  red\n",
    "        [89, 47, 95],  #'sofa'  ->  purple\n",
    "        [81, 109, 114],  #'board'   ->  grey\n",
    "        [233, 233, 229],  #'clutter'  ->  light grey\n",
    "        [0, 0, 0],  # unlabelled .->. black\n",
    "    ]\n",
    "\n",
    "CLASSES = [\n",
    "    'ceiling',\n",
    "    'floor',\n",
    "    'wall',\n",
    "    'beam',\n",
    "    'column',\n",
    "    'window',\n",
    "    'door',\n",
    "    'chair',\n",
    "    'table',\n",
    "    'bookcase',\n",
    "    'sofa',\n",
    "    'board',\n",
    "    'clutter',\n",
    "    'unlabelled',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import *\n",
    "from torch_points3d.core.data_transform import *\n",
    "from torch_points3d.core.data_transform.multimodal.image import *\n",
    "from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "from torch_points3d.datasets.base_dataset_multimodal import BaseDatasetMM\n",
    "\n",
    "def sample_real_data(tg_dataset, idx=0):\n",
    "    \"\"\"\n",
    "    Temporarily remove the 3D and 2D transforms affecting the point \n",
    "    positions and images from the dataset to better visualize points \n",
    "    and images relative positions.\n",
    "    \"\"\"\n",
    "    transform = tg_dataset.transform\n",
    "    tg_dataset.transform = BaseDataset.remove_transform(transform, [Center, RandomNoise,\n",
    "        RandomRotate, RandomScaleAnisotropic, RandomSymmetry, DropFeature, AddFeatsByKeys])\n",
    "    \n",
    "    transform_image = tg_dataset.transform_image\n",
    "#     tg_dataset.transform_image = BaseDatasetMM.remove_multimodal_transform(transform_image, [ToFloatImage, Normalize, AddPixelHeightFeature,])\n",
    "#     tg_dataset.transform_image = BaseDatasetMM.remove_multimodal_transform(transform_image, [ToFloatImage, Normalize, PickImagesFromMappingArea, AddPixelHeightFeature, ])\n",
    "#     tg_dataset.transform_image = BaseDatasetMM.remove_multimodal_transform(transform_image, [ToFloatImage, Normalize, PickImagesFromMappingArea, AddPixelHeightFeature,PickImagesFromMemoryCredit ])\n",
    "    tg_dataset.transform_image = BaseDatasetMM.remove_multimodal_transform(transform_image, [ToFloatImage, Normalize, AddPixelHeightFeature,PickImagesFromMemoryCredit ])\n",
    "\n",
    "    out = tg_dataset[idx]\n",
    "    \n",
    "    tg_dataset.transform = transform\n",
    "    tg_dataset.transform_image = transform_image\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "\n",
    "# Set root to the DATA drive, where the data was downloaded\n",
    "# DATA_ROOT = '/mnt/fa444ffd-fdb4-4701-88e7-f00297a8e29b/projects/datasets/s3dis'  # ???\n",
    "# DATA_ROOT = '/media/drobert-admin/DATA/datasets/s3dis'  # IGN DATA\n",
    "DATA_ROOT = '/media/drobert-admin/DATA2/datasets/s3dis'  # IGN DATA2\n",
    "# DATA_ROOT = '/var/data/drobert/datasets/s3dis'  # AI4GEO\n",
    "# DATA_ROOT = '/home/qt/robertda/scratch/datasets/s3dis'  # CNES\n",
    "# DATA_ROOT = '/raid/datasets/pointcloud/data/s3dis'  # ENGIE\n",
    "\n",
    "overrides = [\n",
    "    'task=segmentation',\n",
    "    'data=segmentation/multimodal/s3disfused/area1-office1_no3d_5cm_768x384-exact_no-pixel-height',\n",
    "    'models=segmentation/multimodal/no3d',\n",
    "    'model_name=RGB_ResNet18PPM_mean-feat',\n",
    "    'data.fold=1',\n",
    "    'data.sample_per_epoch=8',\n",
    "    f\"data.dataroot={os.path.join(DATA_ROOT, '5cm_exact_768x384')}\",\n",
    "]\n",
    "\n",
    "cfg = hydra_read(overrides)\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load S3DIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "    \n",
    "dataset = S3DISFusedDataset(cfg.data)\n",
    "# print(dataset)\n",
    "\n",
    "print(f\"Time = {time() - start:0.1f} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multimodal spherical sample\n",
    "# mm_data = sample_real_data(dataset.test_dataset[0], idx=100)\n",
    "# mm_data = sample_real_data(dataset.train_dataset)\n",
    "# mm_data = sample_real_data(dataset.val_dataset)\n",
    "mm_data = sample_real_data(dataset.test_dataset[0], idx=1)\n",
    "print(mm_data)\n",
    "\n",
    "credit_used = sum([np.prod(im.img_size) * im.num_views for im in mm_data.modalities['image']])\n",
    "credit_max = dataset.train_transform_image.transforms[-1].credit\n",
    "print(f\"Used pixel credit: {credit_used} / {credit_max} = {credit_used / credit_max * 100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data, class_names=CLASSES, class_colors=OBJECT_COLOR, figsize=1000, voxel=0.05, show_3d=True, show_2d=True, color_mode='y', alpha=5, pointsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tp3d_dev] *",
   "language": "python",
   "name": "conda-env-tp3d_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
