{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "_ = torch.cuda.is_available()\n",
    "_ = torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "\n",
    "# Set root to the DATA drive, where the data was downloaded\n",
    "# DATA_ROOT = '/mnt/fa444ffd-fdb4-4701-88e7-f00297a8e29b/projects/datasets/kitti360'  # ???\n",
    "# DATA_ROOT = '/media/drobert-admin/DATA/datasets/kitti360'  # IGN DATA\n",
    "# DATA_ROOT = '/media/drobert-admin/DATA2/datasets/kitti360'  # IGN DATA2\n",
    "# DATA_ROOT = '/var/data/drobert/datasets/kitti360'  # AI4GEO\n",
    "# DATA_ROOT = '/home/qt/robertda/scratch/datasets/kitti360'  # CNES\n",
    "DATA_ROOT = '/raid/dataset/pointcloud/data/kitti360'  # ENGIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run KITTI360 resolution=5cm exp=avg-rgb_6k\n",
      "invalid syntax (<string>, line 1)\n",
      "  run 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712598abc2e648e6a858726c9e9f0dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_dir = '/workspace/projects/torch-points3d/outputs/'\n",
    "result_dir = '/raid/dataset/pointcloud/data/kitti360/results'\n",
    "\n",
    "# ('5cm', 'modelname',   out_dir + '____', '___'),\n",
    "\n",
    "checkpoints = [\n",
    "#     ('5cm', 'Res16UNet34', out_dir + '2021-11-09/09-10-01', 'xyzrgb'),\n",
    "#     ('5cm', 'Res16UNet34', out_dir + '2021-11-16/09-40-20', 'xyzrgb_40ep_6k'),\n",
    "#     ('5cm', 'Res16UNet34', out_dir + '2022-01-15/10-11-10', 'xyzrgb_60ep_6k'),\n",
    "    \n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes', out_dir + '2021-11-16/18-36-13', 'pyramid')\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate', out_dir + '2021-12-11/15-48-03', 'interpolate_pyramid'),\n",
    "\n",
    "#     ('5cm', 'Res16UNet34', out_dir + '2021-11-13/16-02-16', 'xyzrgb_60ep_12k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate', out_dir + '2022-01-21/15-39-56', 'interpolate_pyramid_60ep_12k'),\n",
    "#     ('5cm', 'Res16UNet34-L4-early-cityscapes-interpolate', out_dir + '2022-01-19/13-36-32', 'interpolate_l4_60ep_12k'),\n",
    "  \n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-max-cityscapes-interpolate', out_dir + '22022-01-23/22-15-32', 'interpolate_pyramid_max_12k'),\n",
    "\n",
    "    \n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate-group1', out_dir + '2022-01-25/23-49-15', 'interpolate_pyramid_group1_6k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-fromscratch-interpolate', out_dir + '2022-01-25/16-02-03', 'interpolate_pyramid_fromscratch_6k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate', out_dir + '2022-02-08/14-07-32', 'interpolate_pyramid_704x188_6k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate-nogating', out_dir + '2022-02-08/14-05-14', 'interpolate_pyramid_nogating_6k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-cityscapes-interpolate', out_dir + '2022-02-07/19-24-19', 'interpolate_pyramid_nodynamicbatch_6k'),\n",
    "#     ('5cm', 'Res16UNet34-PointPyramid-early-max-cityscapes-interpolate', out_dir + '2021-12rgb_6k'),\n",
    "#     ('5cm', 'RGB_PointPyramid-cityscapes-interpolate', out_dir + '2022-02-11/14-44-03', 'rgb_6k'),\n",
    "#     ('5cm', 'ResUNet34-PointPyramid-early-cityscapes-interpolate', out_dir + '2022-02-10/17-22/19-08-10', 'interpolate_pyramid_max_6k'),\n",
    "#     ('5cm', 'Res16UNet34-mean-RGB-early', out_dir + '2022-02-11/09-21-56', 'avg--38-50', 'smaller-backbone_6k'),\n",
    "    \n",
    "#     ('5cm', 'Res16UNet34', out_dir + '2022-02-09/17-03-49', 'xyz_6k'),\n",
    "       \n",
    "]\n",
    "\n",
    "# split = 'test'\n",
    "split = 'val'\n",
    "n_votes = 1\n",
    "# sample_res = 3\n",
    "sample_res = 6  # almost equivalent, faster but -0.15 mIoU, roughly\n",
    "batch_size = 8\n",
    "# batch_size = 12\n",
    "\n",
    "for resolution, model_name, directory, exp_name in checkpoints:\n",
    "    \n",
    "    exp_name = model_name if exp_name is None else exp_name\n",
    "    \n",
    "    print(f'Run KITTI360 resolution={resolution} exp={exp_name}')\n",
    "    \n",
    "    overrides = [\n",
    "        f'model_name={model_name}',\n",
    "        f\"checkpoint_dir={directory}\",\n",
    "        'voting_runs=1',\n",
    "        'tracker_options.full_res=True',\n",
    "        f'tracker_options.make_submission={split == \"test\"}',\n",
    "        'precompute_multi_scale=False',\n",
    "        'num_workers=4',\n",
    "        f'batch_size={batch_size}',\n",
    "        f'cuda={I_GPU}',\n",
    "        'weight_name=last',\n",
    "        f'+data.eval_sample_res={sample_res}'\n",
    "    ]\n",
    "    \n",
    "    cfg = hydra_read(overrides, config_name='eval')\n",
    "    \n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    \n",
    "    from torch_points3d.trainer import Trainer\n",
    "    \n",
    "    trainer = Trainer(cfg)\n",
    "    \n",
    "    # Update the val and test transforms to match train transforms for inference-time augmentation\n",
    "    trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "    \n",
    "    if trainer._model.is_multimodal and exp_name != 'interpolate_pyramid_nodynamicbatch_6k':\n",
    "        trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "        trainer._dataset.test_dataset[0].transform_image.transforms[3].use_coverage = False\n",
    "        trainer._dataset.test_dataset[0].transform_image.transforms[3].credit = int(1408 * 376 * 4 * 2)\n",
    "    \n",
    "    trainer._cfg.voting_runs = n_votes    \n",
    "    \n",
    "#     for i_try in range(4):\n",
    "    for i_try in range(1):\n",
    "        print(f'  run {i_try}...')\n",
    "        trainer.eval(stage_name=split)\n",
    "        torch.save(trainer._tracker._full_confusion_matrix, f'{result_dir}/{exp_name}_{split}_{resolution}_sample-res-{sample_res}_votes-{trainer._cfg.voting_runs}_{i_try}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._tracker._full_vote_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = torch.load(f'{result_dir}/{exp_name}_{split}_{resolution}_{i_try}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' & '.join([str(x) for x in np.round(cm.get_intersection_union_per_class()[0] * 100, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = trainer._dataset.val_dataset\n",
    "# val_dataset.transform = trainer._dataset.train_dataset.transform\n",
    "# val_dataset.transform_image = trainer._dataset.train_dataset.transform_image\n",
    "# val_dataset.transform_image.transforms[3].use_coverage = False\n",
    "# val_dataset.transform_image.transforms[3].credit = int(1408 * 376 * 4 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inference for Baseline\n",
    "# from torch_geometric.data import Batch\n",
    "\n",
    "# model = trainer._model.eval().cuda()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pred_baseline = None\n",
    "#     for i in range(1):\n",
    "#         data = Batch.from_data_list([val_dataset[0]])\n",
    "#         model.set_input(data, model.device)\n",
    "#         model(data)\n",
    "#         if pred_baseline is None:\n",
    "#             pred_baseline = model.output.cpu()\n",
    "#         else:\n",
    "#             pred_baseline += model.output.cpu()\n",
    "#     pred_baseline = pred_baseline.argmax(1)\n",
    "\n",
    "# # Save the prediction for backup\n",
    "# # torch.save(pred_baseline, '/raid/dataset/pointcloud/data/scannet/results/inferences_for_visualization/baseline_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only sample in the first window\n",
    "idx_window = 0\n",
    "num_samples = val_dataset.sampling_sizes[idx_window]\n",
    "num_raw_points = val_dataset.window_raw_sizes[idx_window]\n",
    "votes = torch.zeros(num_raw_points, val_dataset.num_classes)\n",
    "\n",
    "# Inference for Baseline\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = trainer._model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i_cylinder in tqdm(range(num_samples)):\n",
    "\n",
    "        data = Batch.from_data_list([val_dataset[i_cylinder]])\n",
    "        model.set_input(data, model.device)\n",
    "        model(data)\n",
    "        y = model.output.cpu()\n",
    "\n",
    "        idx_seen = data.origin_id\n",
    "        votes[idx_seen] += y\n",
    "pred_baseline = votes.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pred, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/baseline_y_pred_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only sample in the first window\n",
    "idx_window = 0\n",
    "num_samples = val_dataset.sampling_sizes[idx_window]\n",
    "num_raw_points = val_dataset.window_raw_sizes[idx_window]\n",
    "votes = torch.zeros(num_raw_points, val_dataset.num_classes)\n",
    "\n",
    "# Inference for Ours\n",
    "from torch_points3d.core.multimodal.data import MMData, MMBatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = trainer._model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i_cylinder in tqdm(range(num_samples)):\n",
    "\n",
    "        mm_data = MMBatch.from_mm_data_list([val_dataset[i_cylinder]])\n",
    "        model.set_input(mm_data, model.device)\n",
    "        model(mm_data)\n",
    "        y = model.output.cpu()\n",
    "        idx_seen = mm_data.data.origin_id\n",
    "        votes[idx_seen] += y\n",
    "pred_ours = votes.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gt = val_dataset.buffer[idx_window].data.clone()\n",
    "\n",
    "data_baseline = val_dataset.buffer[idx_window].data.clone()\n",
    "data_baseline.y = pred_baseline[data_baseline.origin_id]\n",
    "\n",
    "data_ours = val_dataset.buffer[idx_window].data.clone()\n",
    "data_ours.y = pred_ours[data_ours.origin_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(data_gt, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/data_gt.pt')\n",
    "# torch.save(data_baseline, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/data_baseline.pt')\n",
    "# torch.save(data_ours, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/data_ours.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data, hex_to_tensor\n",
    "from torch_points3d.datasets.segmentation.kitti360_config import CLASS_NAMES, CLASS_COLORS\n",
    "from torch_points3d.core.multimodal.data import MMData\n",
    "from torch_points3d.core.multimodal.image import ImageData\n",
    "\n",
    "data_gt.mapping_index = torch.arange(data_gt.num_nodes)\n",
    "mm_data_gt = MMData(data_gt, image=ImageData([SameSettingImageData()]))\n",
    "\n",
    "data_baseline.mapping_index = torch.arange(data_baseline.num_nodes)\n",
    "mm_data_baseline = MMData(data_baseline, image=ImageData([SameSettingImageData()]))\n",
    "\n",
    "data_ours.mapping_index = torch.arange(data_ours.num_nodes)\n",
    "mm_data_ours = MMData(data_ours, image=ImageData([SameSettingImageData()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mm_data_gt, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/mm_data_gt.pt')\n",
    "# torch.save(mm_data_baseline, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/mm_data_baseline.pt')\n",
    "# torch.save(mm_data_ours, '/raid/dataset/pointcloud/data/kitti360/results/inference_for_visualization/mm_data_ours.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colorize in red the areas of interest for us \n",
    "idx_ideal = (mm_data_ours.y == mm_data_gt.y) & (mm_data_baseline.y != mm_data_gt.y)\n",
    "mm_data_gt.data.rgb[idx_ideal] = torch.Tensor([1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_gt, figsize=1000, pointsize=3, voxel=1, show_2d=False, front='map', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_baseline, figsize=1000, pointsize=3, voxel=1, show_2d=False, front='map', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_ours, figsize=1000, pointsize=3, voxel=1, show_2d=False, front='map', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_range = (1060 < mm_data_ours.data.pos[:, 0]) & (mm_data_ours.data.pos[:, 0] < 1100)\n",
    "mm_data_gt_range = mm_data_gt[in_range]\n",
    "mm_data_baseline_range = mm_data_baseline[in_range]\n",
    "mm_data_ours_range = mm_data_ours[in_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_gt_range, figsize=1000, pointsize=3, voxel=0.1, show_2d=False, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_baseline_range, figsize=1000, pointsize=3, voxel=0.1, show_2d=False, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data_ours_range, figsize=1000, pointsize=3, voxel=0.1, show_2d=False, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=2, max_points=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick visualization of overlapping spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = trainer._dataset._test_loaders[0]\n",
    "trainer._dataset.test_dataset[0].transform = None\n",
    "loader.num_workers = 0\n",
    "for i, data in enumerate(loader):\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data, hex_to_tensor, PALETTE\n",
    "from torch_points3d.core.multimodal.data import MMData\n",
    "from torch_points3d.core.multimodal.image import SameSettingImageData, ImageData\n",
    "\n",
    "colors = torch.cat([hex_to_tensor(x) for x in PALETTE]).view(-1, 3)\n",
    "\n",
    "data.rgb = torch.ones_like(data.rgb)\n",
    "\n",
    "for i_batch in range(loader.batch_size):\n",
    "    start = data.__slices__['rgb'][i_batch]\n",
    "    end = data.__slices__['rgb'][i_batch + 1]\n",
    "    data.rgb[start:end] = data.rgb[start:end] * 0.5 + 0.5 * colors[i_batch % colors.shape[0]]\n",
    "\n",
    "data.mapping_index = torch.arange(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data = MMData(data=data, image=ImageData([SameSettingImageData()]))\n",
    "visualize_mm_data(mm_data, figsize=600, pointsize=3, voxel=0.5, show_2d=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mini_data in data.to_data_list():\n",
    "    mm_data = MMData(data=mini_data, image=ImageData([SameSettingImageData()]))\n",
    "    visualize_mm_data(mm_data, figsize=600, pointsize=3, voxel=0.5, show_2d=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick visualization of submited window predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.datasets.segmentation.kitti360 import read_kitti360_window, ID2TRAINID\n",
    "from torch_points3d.core.multimodal import MMData, ImageData\n",
    "from torch_points3d.datasets.segmentation.kitti360 import KITTI360_NUM_CLASSES, INV_OBJECT_LABEL, OBJECT_COLOR, IGNORE\n",
    "import os.path as osp\n",
    "\n",
    "i_submission_file = 0\n",
    "\n",
    "# Get the submission file from submission directory\n",
    "_submission_dir = '/raid/dataset/pointcloud/data/kitti360/results/submissions/xyzrgb/2021-11-11_9-19-56'\n",
    "path = sorted(glob.glob(_submission_dir + '/*.npy'))[i_submission_file]\n",
    "\n",
    "# Add ignored class in black\n",
    "class_names = [INV_OBJECT_LABEL[i] for i in range(KITTI360_NUM_CLASSES)] + ['ignored']\n",
    "class_colors = np.append(OBJECT_COLOR, np.zeros((1, 3), dtype=np.uint8), axis=0)\n",
    "\n",
    "# Recover window name and associated raw file\n",
    "window_name = osp.splitext(osp.basename(path)[5:])[0]\n",
    "idx_window = [osp.splitext(osp.basename(x))[0] for x in trainer._dataset.test_dataset[0].raw_3d_paths].index(window_name)\n",
    "raw_window_path = trainer._dataset.test_dataset[0].raw_3d_paths[idx_window]\n",
    "\n",
    "# Load labels\n",
    "y = torch.from_numpy(ID2TRAINID[np.load(path)])\n",
    "\n",
    "# Load raw data\n",
    "data = read_kitti360_window(raw_window_path, xyz=True, rgb=True, remap=True)\n",
    "data.y = y\n",
    "data.mapping_index = torch.arange(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data = MMData(data=data, image=ImageData([SameSettingImageData()]))\n",
    "visualize_mm_data(mm_data, figsize=1000, pointsize=3, voxel=0.5, show_2d=False, class_names=class_names, class_colors=class_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp3d",
   "language": "python",
   "name": "tp3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
