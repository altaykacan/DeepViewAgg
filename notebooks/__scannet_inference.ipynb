{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "# from torch_points3d.datasets.segmentation.scannet import ScannetDataset, IGNORE_LABEL\n",
    "from torch_points3d.datasets.segmentation.multimodal.scannet import ScannetDatasetMM, IGNORE_LABEL\n",
    "\n",
    "_ = torch.cuda.is_available()\n",
    "_ = torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "\n",
    "# Set root to the DATA drive, where the data was downloaded\n",
    "# DATA_ROOT = '/mnt/fa444ffd-fdb4-4701-88e7-f00297a8e29b/projects/datasets/s3dis'  # ???\n",
    "# DATA_ROOT = '/media/drobert-admin/DATA/datasets/s3dis'  # IGN DATA\n",
    "# DATA_ROOT = '/media/drobert-admin/DATA2/datasets/s3dis'  # IGN DATA2\n",
    "# DATA_ROOT = '/var/data/drobert/datasets/s3dis'  # AI4GEO\n",
    "# DATA_ROOT = '/home/qt/robertda/scratch/datasets/s3dis'  # CNES\n",
    "DATA_ROOT = '/raid/dataset/pointcloud/data/scannet'  # ENGIE\n",
    "\n",
    "# XYZ+RGB\n",
    "overrides = [\n",
    "#     'model_name=Res16UNet34-L4-early',\n",
    "    \n",
    "#     'model_name=Res16UNet34-L4-early-ade20k-interpolate',\n",
    "    'model_name=Res16UNet34-PointPyramid-early-ade20k-interpolate',\n",
    "    \n",
    "#     f\"checkpoint_dir={'/workspace/projects/torch-points3d/outputs/2021-10-20/18-43-13'}\",\n",
    "#     f\"checkpoint_dir={'/workspace/projects/torch-points3d/outputs/2021-10-24/23-12-40'}\",\n",
    "    \n",
    "#     f\"checkpoint_dir={'/workspace/projects/torch-points3d/outputs/2021-12-29/18-02-24'}\",\n",
    "    f\"checkpoint_dir={'/workspace/projects/torch-points3d/outputs/2021-12-11/15-51-10'}\",\n",
    "    \n",
    "    'voting_runs=1',\n",
    "    'tracker_options.full_res=True',\n",
    "#     'tracker_options.make_submission=True',\n",
    "    'precompute_multi_scale=False',\n",
    "    'num_workers=4',\n",
    "    'batch_size=4',\n",
    "    f'cuda={I_GPU}',\n",
    "    'weight_name=miou',\n",
    "#     'weight_name=last',\n",
    "]\n",
    "\n",
    "# # XYZRGB\n",
    "# overrides = [\n",
    "#     'model_name=Res16UNet34',\n",
    "#     f\"checkpoint_dir={'/workspace/projects/torch-points3d/outputs/2021-11-05/23-21-24'}\",  # 3cm\n",
    "#     'voting_runs=1',\n",
    "#     'tracker_options.full_res=True',\n",
    "#  #   'tracker_options.make_submission=True',\n",
    "#     'precompute_multi_scale=False',\n",
    "#     'num_workers=4',\n",
    "#     'batch_size=4',\n",
    "#     f'cuda={I_GPU}',\n",
    "# #     'weight_name=miou',\n",
    "#     'weight_name=last',\n",
    "# ]\n",
    "\n",
    "cfg = hydra_read(overrides, config_name='eval')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg))# Load S3DIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = trainer._dataset.test_dataset[0].transform\n",
    "test_transform_image = trainer._dataset.test_dataset[0].transform_image\n",
    "val_transform = trainer._dataset.val_dataset.transform\n",
    "val_transform_image = trainer._dataset.val_dataset.transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the val and test transforms to match train transforms for inference-time augmentation\n",
    "trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "\n",
    "trainer._dataset.val_dataset.transform = trainer._dataset.train_dataset.transform\n",
    "trainer._dataset.val_dataset.transform_image = trainer._dataset.train_dataset.transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = 1920000\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = 1920000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = int(1920000 / 4)\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = int(1920000 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[3].sigma = 0.02\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.saturation = [0.8, 1.2]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.brightness = [0.8, 1.2]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.contrast = [0.8, 1.2]\n",
    "\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.val_dataset.transform_image.transforms[3].sigma = 0.02\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.saturation = [0.8, 1.2]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.brightness = [0.8, 1.2]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.contrast = [0.8, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[3].sigma = 0.03\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.saturation = [0.6, 1.4]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.brightness = [0.6, 1.4]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.contrast = [0.6, 1.4]\n",
    "\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.val_dataset.transform_image.transforms[3].sigma = 0.03\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.saturation = [0.6, 1.4]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.brightness = [0.6, 1.4]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.contrast = [0.6, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[3].sigma = 0.01\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.saturation = [0.9, 1.1]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.brightness = [0.9, 1.1]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.contrast = [0.9, 1.1]\n",
    "\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.val_dataset.transform_image.transforms[3].sigma = 0.01\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.saturation = [0.9, 1.1]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.brightness = [0.9, 1.1]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.contrast = [0.9, 1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[3].sigma = 0.005\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.saturation = [0.95, 1.05]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.brightness = [0.95, 1.05]\n",
    "trainer._dataset.test_dataset[0].transform_image.transforms[4].transform.contrast = [0.95, 1.05]\n",
    "\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].use_coverage = False\n",
    "trainer._dataset.val_dataset.transform_image.transforms[2].credit = int(1920000 * 2)\n",
    "trainer._dataset.val_dataset.transform_image.transforms[3].sigma = 0.005\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.saturation = [0.95, 1.05]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.brightness = [0.95, 1.05]\n",
    "trainer._dataset.val_dataset.transform_image.transforms[4].transform.contrast = [0.95, 1.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 / 2)\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.02\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.8, 1.2]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.8, 1.2]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.8, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 * 2)\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.02\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.9, 1.1]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.9, 1.1]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.9, 1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 / 2)\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.01\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.95, 1.05]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.95, 1.05]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.95, 1.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 / 4)\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.001\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.99, 1.01]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.99, 1.01]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.99, 1.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 / 2)\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.2\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.1, 1.9]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.1, 1.9]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.1, 1.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[-1].mean = [0, 0, 0]\n",
    "# trainer._dataset.test_dataset[0].transform_image.transforms[-1].std = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer._cfg.tracker_options.full_res = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._cfg.voting_runs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation inference\n",
    "trainer.eval(stage_name=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test inference\n",
    "# trainer.eval(stage_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(trainer._tracker._full_confusion_matrix, '/raid/dataset/pointcloud/data/scannet/results/xyz+rgb_3cm_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference visualizations for ScanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._dataset.val_dataset.transform.transforms = val_transform.transforms[:-1]\n",
    "trainer._dataset.val_dataset.transform_image = val_transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for Baseline\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "model = trainer._model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_baseline = None\n",
    "    for i in range(1):\n",
    "        data = Batch.from_data_list([trainer._dataset.val_dataset[0]])\n",
    "        model.set_input(data, model.device)\n",
    "        model(data)\n",
    "        if pred_baseline is None:\n",
    "            pred_baseline = model.output.cpu()\n",
    "        else:\n",
    "            pred_baseline += model.output.cpu()\n",
    "    pred_baseline = pred_baseline.argmax(1)\n",
    "\n",
    "# Save the prediction for backup\n",
    "# torch.save(pred_baseline, '/raid/dataset/pointcloud/data/scannet/results/inferences_for_visualization/baseline_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for Ours\n",
    "from torch_points3d.core.multimodal.data import MMData, MMBatch\n",
    "\n",
    "model = trainer._model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_ours = None\n",
    "    for i in range(1):\n",
    "        mm_data = MMBatch.from_mm_data_list([trainer._dataset.val_dataset[0]])\n",
    "        model.set_input(mm_data, model.device)\n",
    "        model(mm_data)\n",
    "        if pred_ours is None:\n",
    "            pred_ours = model.output.cpu()\n",
    "        else:\n",
    "            pred_ours += model.output.cpu()\n",
    "    pred_ours = pred_ours.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.datasets.segmentation.scannet import VALID_CLASS_IDS, SCANNET_COLOR_MAP, CLASS_LABELS, NUM_CLASSES, IGNORE_LABEL, CLASS_COLORS, CLASS_NAMES\n",
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data\n",
    "\n",
    "def remap_scannet_labels(semantic_label, valid_class_idx=VALID_CLASS_IDS, donotcare_class_ids=[]):\n",
    "    \"\"\"Remaps labels to [0 ; num_labels -1].\"\"\"\n",
    "    new_labels = semantic_label.clone()\n",
    "    mapping_dict = {idx: i for i, idx in enumerate(valid_class_idx)}\n",
    "    for idx in range(NUM_CLASSES):\n",
    "        if idx not in mapping_dict:\n",
    "            mapping_dict[idx] = IGNORE_LABEL\n",
    "    for idx in donotcare_class_ids:\n",
    "        mapping_dict[idx] = IGNORE_LABEL\n",
    "    for source, target in mapping_dict.items():\n",
    "        mask = semantic_label == source\n",
    "        new_labels[mask] = target\n",
    "\n",
    "    broken_labels = new_labels >= len(valid_class_idx)\n",
    "    new_labels[broken_labels] = IGNORE_LABEL\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MMData objects\n",
    "mm_data_gt = mm_data.clone()\n",
    "mm_data_gt.modalities['image'] = mm_data_gt.modalities['image'][0][[]]\n",
    "\n",
    "mm_data_ours = mm_data.clone()\n",
    "mm_data_ours.modalities['image'] = mm_data_ours.modalities['image'][0][[]]\n",
    "mm_data_ours.data.y = pred_ours\n",
    "\n",
    "# mm_data_baseline = mm_data.clone()\n",
    "# mm_data_baseline.modalities['image'] = mm_data_baseline.modalities['image'][0][[]]\n",
    "# mm_data_baseline.data.y = pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.core.multimodal.image import ImageData, SameSettingImageData\n",
    "mm_data_gt = torch.load('/raid/dataset/pointcloud/data/scannet/results/inferences_for_visualization/gt.pt')\n",
    "mm_data_gt.modalities['image'] = ImageData([SameSettingImageData()])\n",
    "visualize_mm_data(mm_data_gt, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, show_2d=False, figsize=1600, pointsize=4, voxel=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data_ours = torch.load('/raid/dataset/pointcloud/data/scannet/results/inferences_for_visualization/ours.pt')\n",
    "mm_data_ours.modalities['image'] = ImageData([SameSettingImageData()])\n",
    "visualize_mm_data(mm_data_ours, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, show_2d=False, figsize=1600, pointsize=4, voxel=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data_baseline = torch.load('/raid/dataset/pointcloud/data/scannet/results/inferences_for_visualization/baseline.pt')\n",
    "mm_data_baseline.modalities['image'] = ImageData([SameSettingImageData()])\n",
    "visualize_mm_data(mm_data_baseline, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, show_2d=False, figsize=1600, pointsize=4, voxel=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - x2 credit - train aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - even softer 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - even softer 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - softer 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=5 - ÷4 credit - harder 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - harder 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - milder 2D aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=5 - ÷4 credit - train aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit - train aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit AGAIN\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=5 - ÷4 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷6 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷8 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷4 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - ÷2 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - x2 credit\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=5 - no aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - no aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=1 - no aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - softer aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=3 - aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=1 - aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XYZ+RGB 5cm Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote=1 - r/2 - x2 credit - aug\n",
    "trainer._tracker.get_metrics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(trainer._tracker._full_confusion, '/raid/dataset/pointcloud/data/scannet/results/xyz+rgb_5cm_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# cm = torch.load('/raid/dataset/pointcloud/data/scannet/results/sparseconv3d_3cm.pt')\n",
    "cm = torch.load('/raid/dataset/pointcloud/data/scannet/results/xyz+rgb_3cm_val.pt')\n",
    "cm.get_average_intersection_union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' & '.join([str(x) for x in np.round((cm.get_intersection_union_per_class()[0]) * 100, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp3d",
   "language": "python",
   "name": "tp3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
