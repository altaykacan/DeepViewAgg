{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "\n",
    "# Build the 2D image\n",
    "r_img = torch.repeat_interleave(torch.repeat_interleave(torch.LongTensor([1, 0, 0]).view(3,1,1), n, dim=1), n, dim=2)\n",
    "g_img = torch.repeat_interleave(torch.repeat_interleave(torch.LongTensor([0, 1, 0]).view(3,1,1), n, dim=1), n, dim=2)\n",
    "b_img = torch.repeat_interleave(torch.repeat_interleave(torch.LongTensor([0, 0, 1]).view(3,1,1), n, dim=1), n, dim=2)\n",
    "y_img = torch.repeat_interleave(torch.repeat_interleave(torch.LongTensor([1, 1, 0]).view(3,1,1), n, dim=1), n, dim=2)\n",
    "\n",
    "img = torch.cat((torch.cat((r_img, g_img), dim=1), torch.cat((b_img, y_img), dim=1)), dim=2).unsqueeze(0)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(img[0].permute(1,2,0).numpy() * 255)\n",
    "# plt.show()\n",
    "\n",
    "# Build the pixel coordinates\n",
    "x, y = torch.meshgrid(torch.arange(2*n), torch.arange(2*n))\n",
    "pixels = torch.cat((x.reshape((2*n)**2, 1), y.reshape((2*n)**2, 1)), dim=1)\n",
    "\n",
    "# Build the point and image indices\n",
    "img_idx = torch.zeros((2*n)**2).long()\n",
    "point_idx = torch.arange((2*n)**2)\n",
    "\n",
    "from torch_points3d.datasets.multimodal.image import ImageMapping\n",
    "mappings = ImageMapping.from_dense(point_idx, img_idx, pixels)\n",
    "\n",
    "from torch_points3d.datasets.multimodal.image import ImageData\n",
    "\n",
    "images = ImageData(\n",
    "    path=np.zeros(1, dtype='O'),\n",
    "    pos=torch.Tensor([[n, n, -1]]),\n",
    "    opk=torch.ones((1, 3)),\n",
    "    ref_size=(2*n, 2*n),\n",
    "    images=img,\n",
    "    mappings=mappings)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "pos = torch.cat((x.reshape((2*n)**2, 1), y.reshape((2*n)**2, 1), torch.zeros((2*n)**2, 1).long()), dim=1).float()\n",
    "rgb = img[0, :, pixels[:, 0], pixels[:, 1]].T.float()\n",
    "y = torch.ones(2*n,2*n).long()\n",
    "y[:n, :n] = 0\n",
    "y[n:, :n] = 1\n",
    "y[:n, n:] = 2\n",
    "y[n:, n:] = 3\n",
    "y = y.flatten()\n",
    "data = Data(pos=pos, rgb=rgb, y=y, mapping_index=point_idx)\n",
    "\n",
    "from torch_points3d.datasets.multimodal.data import MMData\n",
    "\n",
    "mm_data = MMData(data, images)\n",
    "\n",
    "# Build class colors for y mode visualization\n",
    "class_colors = [\n",
    "    [255, 0, 0],  # red\n",
    "    [0, 255, 0],  # green\n",
    "    [0, 0, 255],  # blue\n",
    "    [255, 255, 0]]  # yellow\n",
    "\n",
    "from torch_points3d.visualization import visualize_mm_data\n",
    "visualize_mm_data(mm_data, color_mode='y', class_colors=class_colors, figsize=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale 3D\n",
    "from torch_points3d.core.data_transform import GridSampling3D\n",
    "from torch_points3d.core.data_transform.multimodal.image import SelectMappingFromPointId\n",
    "\n",
    "mm_sub = mm_data.clone()\n",
    "\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.mapping_index)\n",
    "mm_sub.data = GridSampling3D(2)(mm_sub.data.clone())\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.mapping_index)\n",
    "idx_sampling = mm_sub.data.mapping_index\n",
    "\n",
    "mm_sub = mm_sub\n",
    "\n",
    "# Subsample the mappings accordingly\n",
    "mm_sub.data , mm_sub.images = SelectMappingFromPointId()(mm_sub.data, mm_sub.images)\n",
    "\n",
    "visualize_mm_data(mm_sub, color_mode='y', class_colors=class_colors, figsize=700)\n",
    "\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.mapping_index)\n",
    "mm_sub.data = GridSampling3D(2*2)(mm_sub.data.clone())\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.mapping_index)\n",
    "idx_sampling = idx_sampling[mm_sub.data.mapping_index]\n",
    "\n",
    "mm_sub = mm_sub\n",
    "\n",
    "# Subsample the mappings accordingly\n",
    "mm_sub.data , mm_sub.images = SelectMappingFromPointId()(mm_sub.data, mm_sub.images)\n",
    "\n",
    "visualize_mm_data(mm_sub, color_mode='y', class_colors=class_colors, figsize=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale 3D\n",
    "from torch_points3d.core.data_transform import GridSampling3D\n",
    "from torch_points3d.core.data_transform.multimodal.image import SelectMappingFromPointId\n",
    "\n",
    "mm_sub = mm_data.clone()\n",
    "\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.point_index)\n",
    "# mm_sub.data = GridSampling3D(2)(mm_sub.data.clone())\n",
    "# print(mm_sub.data.num_nodes, mm_sub.data.point_index)\n",
    "\n",
    "mm_sub = mm_sub[idx_sampling]\n",
    "\n",
    "# Subsample the mappings accordingly\n",
    "mm_sub.data , mm_sub.images = SelectMappingFromPointId()(mm_sub.data, mm_sub.images)\n",
    "\n",
    "visualize_mm_data(mm_sub, color_mode='y', class_colors=class_colors, figsize=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale 3D with 'merge' mode\n",
    "from torch_points3d.core.data_transform import GridSampling3D\n",
    "from torch_cluster import grid_cluster\n",
    "from torch_geometric.nn import voxel_grid\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster\n",
    "\n",
    "voxel = 32\n",
    "\n",
    "mm_sub = mm_data.clone()\n",
    "\n",
    "# Get the cluster indices for grid sampling\n",
    "coords = torch.round((mm_sub.data.pos) / voxel)\n",
    "if \"batch\" not in mm_sub.data:\n",
    "    cluster = grid_cluster(coords, torch.tensor([1, 1, 1]))\n",
    "else:\n",
    "    cluster = voxel_grid(coords, mm_sub.data.batch, 1)\n",
    "cluster, _ = consecutive_cluster(cluster)\n",
    "\n",
    "# Actual 3D sampling\n",
    "mm_sub.data = GridSampling3D(voxel)(mm_sub.data.clone())\n",
    "\n",
    "# Subsample the mappings accordingly with 'merge' mocde\n",
    "mm_sub.images.mappings = mm_sub.images.mappings.select_points(cluster, merge=True)\n",
    "    \n",
    "# Reset the mapping_index\n",
    "# Remark : unlike SelectMappingFromPointId, we don't need to search for\n",
    "# potentially unseen images when 'merge=True', because the subsampling\n",
    "# index implies that all points are merged into a new one, so no \n",
    "# mappings should be lost in the process.\n",
    "mm_sub.data.mapping_index = torch.arange(mm_sub.data.num_nodes)\n",
    "\n",
    "visualize_mm_data(mm_sub, color_mode='rgb', class_colors=class_colors, figsize=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tp3d_dev] *",
   "language": "python",
   "name": "conda-env-tp3d_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
